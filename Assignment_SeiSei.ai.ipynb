{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Implementation of GAN from Scratch in Pytorch on MNIST Dataset along with Early Stopping to avoid overfitting"
      ],
      "metadata": {
        "id": "RNIyo55iHBK2"
      },
      "id": "RNIyo55iHBK2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the approach given in paper \"[VGAN: Generalizing MSE GAN and WGAN-GP\n",
        "for Robot Fault Diagnosis](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9760080)\"\n",
        "They have define an innovative approach for Early stopping in GANs by defining a ML model like Random Forest and then use it for the validation part and testing of Early stopping criteria."
      ],
      "metadata": {
        "id": "_mjNzGkWm2lq"
      },
      "id": "_mjNzGkWm2lq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8ee68e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:48.800080Z",
          "iopub.status.busy": "2023-09-02T18:18:48.799768Z",
          "iopub.status.idle": "2023-09-02T18:18:52.352189Z",
          "shell.execute_reply": "2023-09-02T18:18:52.351244Z"
        },
        "papermill": {
          "duration": 3.56239,
          "end_time": "2023-09-02T18:18:52.354526",
          "exception": false,
          "start_time": "2023-09-02T18:18:48.792136",
          "status": "completed"
        },
        "tags": [],
        "id": "6c8ee68e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import tqdm\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "163e5875",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:52.370496Z",
          "iopub.status.busy": "2023-09-02T18:18:52.368862Z",
          "iopub.status.idle": "2023-09-02T18:18:52.375444Z",
          "shell.execute_reply": "2023-09-02T18:18:52.374587Z"
        },
        "papermill": {
          "duration": 0.015827,
          "end_time": "2023-09-02T18:18:52.377214",
          "exception": false,
          "start_time": "2023-09-02T18:18:52.361387",
          "status": "completed"
        },
        "tags": [],
        "id": "163e5875"
      },
      "outputs": [],
      "source": [
        "CUDA = True\n",
        "DATA_PATH = './data'\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_CHANNEL = 1\n",
        "Z_DIM = 100\n",
        "G_HIDDEN = 64\n",
        "X_DIM = 64\n",
        "D_HIDDEN = 64\n",
        "EPOCH_NUM = 5\n",
        "REAL_LABEL = 1\n",
        "FAKE_LABEL = 0\n",
        "lr = 2e-4\n",
        "seed = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da1f6476",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:52.390822Z",
          "iopub.status.busy": "2023-09-02T18:18:52.390520Z",
          "iopub.status.idle": "2023-09-02T18:18:52.463728Z",
          "shell.execute_reply": "2023-09-02T18:18:52.462845Z"
        },
        "papermill": {
          "duration": 0.082129,
          "end_time": "2023-09-02T18:18:52.465702",
          "exception": false,
          "start_time": "2023-09-02T18:18:52.383573",
          "status": "completed"
        },
        "tags": [],
        "id": "da1f6476"
      },
      "outputs": [],
      "source": [
        "CUDA = CUDA and torch.cuda.is_available()\n",
        "print(\"PyTorch version: {}\".format(torch.__version__))\n",
        "if CUDA:\n",
        "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
        "\n",
        "if CUDA:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
        "cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0934c10",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:52.480108Z",
          "iopub.status.busy": "2023-09-02T18:18:52.479244Z",
          "iopub.status.idle": "2023-09-02T18:18:53.757937Z",
          "shell.execute_reply": "2023-09-02T18:18:53.756985Z"
        },
        "papermill": {
          "duration": 1.288203,
          "end_time": "2023-09-02T18:18:53.760266",
          "exception": false,
          "start_time": "2023-09-02T18:18:52.472063",
          "status": "completed"
        },
        "tags": [],
        "id": "d0934c10"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "\n",
        "train_data = datasets.MNIST(root=DATA_PATH,\n",
        "                                train=True,\n",
        "                                download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                     transforms.Resize(X_DIM),\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.5,), (0.5,))\n",
        "                     ]))\n",
        "\n",
        "test_data = datasets.MNIST(root=DATA_PATH,\n",
        "                            train=False,\n",
        "                            download=True,\n",
        "                            transform=transforms.Compose([\n",
        "                     transforms.Resize(X_DIM),\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.5,), (0.5,))\n",
        "                     ]))\n",
        "\n",
        "num_train = len(train_data)\n",
        "valid_size = 0.2\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# load training data in batches\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            sampler=train_sampler,\n",
        "                                            num_workers=0)\n",
        "\n",
        "# load validation data in batches\n",
        "valid_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            sampler=valid_sampler,\n",
        "                                            num_workers=0)\n",
        "\n",
        "# load test data in batches\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409eeee7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:53.777737Z",
          "iopub.status.busy": "2023-09-02T18:18:53.777433Z",
          "iopub.status.idle": "2023-09-02T18:18:57.248966Z",
          "shell.execute_reply": "2023-09-02T18:18:57.247959Z"
        },
        "papermill": {
          "duration": 3.483559,
          "end_time": "2023-09-02T18:18:57.251898",
          "exception": false,
          "start_time": "2023-09-02T18:18:53.768339",
          "status": "completed"
        },
        "tags": [],
        "id": "409eeee7"
      },
      "outputs": [],
      "source": [
        "real_batch = next(iter(train_loader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918b5d4b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:57.272604Z",
          "iopub.status.busy": "2023-09-02T18:18:57.272277Z",
          "iopub.status.idle": "2023-09-02T18:18:57.278095Z",
          "shell.execute_reply": "2023-09-02T18:18:57.277190Z"
        },
        "papermill": {
          "duration": 0.018447,
          "end_time": "2023-09-02T18:18:57.280081",
          "exception": false,
          "start_time": "2023-09-02T18:18:57.261634",
          "status": "completed"
        },
        "tags": [],
        "id": "918b5d4b"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa40e2e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:57.300404Z",
          "iopub.status.busy": "2023-09-02T18:18:57.299576Z",
          "iopub.status.idle": "2023-09-02T18:18:57.308347Z",
          "shell.execute_reply": "2023-09-02T18:18:57.307481Z"
        },
        "papermill": {
          "duration": 0.020987,
          "end_time": "2023-09-02T18:18:57.310298",
          "exception": false,
          "start_time": "2023-09-02T18:18:57.289311",
          "status": "completed"
        },
        "tags": [],
        "id": "1aa40e2e"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input layer\n",
        "            nn.ConvTranspose2d(Z_DIM, G_HIDDEN * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN * 8),\n",
        "            nn.ReLU(True),\n",
        "            # 1st hidden layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN * 8, G_HIDDEN * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN * 4),\n",
        "            nn.ReLU(True),\n",
        "            # 2nd hidden layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN * 4, G_HIDDEN * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN * 2),\n",
        "            nn.ReLU(True),\n",
        "            # 3rd hidden layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN * 2, G_HIDDEN, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN),\n",
        "            nn.ReLU(True),\n",
        "            # output layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79095088",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:57.330739Z",
          "iopub.status.busy": "2023-09-02T18:18:57.330446Z",
          "iopub.status.idle": "2023-09-02T18:18:57.338898Z",
          "shell.execute_reply": "2023-09-02T18:18:57.338011Z"
        },
        "papermill": {
          "duration": 0.021295,
          "end_time": "2023-09-02T18:18:57.340862",
          "exception": false,
          "start_time": "2023-09-02T18:18:57.319567",
          "status": "completed"
        },
        "tags": [],
        "id": "79095088"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # 1st layer\n",
        "            nn.Conv2d(IMAGE_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 2nd layer\n",
        "            nn.Conv2d(D_HIDDEN, D_HIDDEN * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(D_HIDDEN * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 3rd layer\n",
        "            nn.Conv2d(D_HIDDEN * 2, D_HIDDEN * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(D_HIDDEN * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 4th layer\n",
        "            nn.Conv2d(D_HIDDEN * 4, D_HIDDEN * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(D_HIDDEN * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # output layer\n",
        "            nn.Conv2d(D_HIDDEN * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1, 1).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13a8b9ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:57.360892Z",
          "iopub.status.busy": "2023-09-02T18:18:57.360259Z",
          "iopub.status.idle": "2023-09-02T18:18:57.426635Z",
          "shell.execute_reply": "2023-09-02T18:18:57.424579Z"
        },
        "papermill": {
          "duration": 0.078617,
          "end_time": "2023-09-02T18:18:57.428786",
          "exception": false,
          "start_time": "2023-09-02T18:18:57.350169",
          "status": "completed"
        },
        "tags": [],
        "id": "13a8b9ff"
      },
      "outputs": [],
      "source": [
        "# Create the generator\n",
        "netG = Generator().to(device)\n",
        "netG.apply(weights_init)\n",
        "print(netG)\n",
        "\n",
        "# Create the discriminator\n",
        "netD = Discriminator().to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d2fc935",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:57.449126Z",
          "iopub.status.busy": "2023-09-02T18:18:57.448857Z",
          "iopub.status.idle": "2023-09-02T18:18:57.455109Z",
          "shell.execute_reply": "2023-09-02T18:18:57.454222Z"
        },
        "papermill": {
          "duration": 0.01877,
          "end_time": "2023-09-02T18:18:57.457113",
          "exception": false,
          "start_time": "2023-09-02T18:18:57.438343",
          "status": "completed"
        },
        "tags": [],
        "id": "1d2fc935"
      },
      "outputs": [],
      "source": [
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that I will use to visualize the progression of the generator\n",
        "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(imgs):\n",
        "    fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(8,8))\n",
        "    count = 0\n",
        "    for y in range(4):\n",
        "        for x in range(4):\n",
        "            img = imgs[count].view(64, 64)\n",
        "            axs[y][x].imshow(img, cmap=\"gray\")\n",
        "            count += 1\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QEdFFo6AnYOF"
      },
      "id": "QEdFFo6AnYOF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no such thing called Early stopping because no one can predict when to stop training of GAN. So, most of the times GAN are train for maximum no. of epochs that are defined."
      ],
      "metadata": {
        "id": "wVQwBhR0jbX3"
      },
      "id": "wVQwBhR0jbX3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "053c90a7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:18:57.477421Z",
          "iopub.status.busy": "2023-09-02T18:18:57.477165Z",
          "iopub.status.idle": "2023-09-02T18:23:15.168910Z",
          "shell.execute_reply": "2023-09-02T18:23:15.167733Z"
        },
        "papermill": {
          "duration": 257.70511,
          "end_time": "2023-09-02T18:23:15.171628",
          "exception": false,
          "start_time": "2023-09-02T18:18:57.466518",
          "status": "completed"
        },
        "tags": [],
        "id": "053c90a7"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "best_accuracy = -1\n",
        "best_epoch = -1\n",
        "random_forest_accuracies = []\n",
        "generated_data=[]\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(EPOCH_NUM):\n",
        "    for i, data in enumerate(tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCH_NUM}')):\n",
        "        # (1) Update the discriminator with real data\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), REAL_LABEL, dtype=torch.float, device=device)\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # (2) Update the discriminator with fake data\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, Z_DIM, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(FAKE_LABEL)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        # (3) Update the generator with fake data\n",
        "        netG.zero_grad()\n",
        "        label.fill_(REAL_LABEL)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, EPOCH_NUM, i, len(train_loader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "       # Discriminator Early Stopping\n",
        "        netG.eval()\n",
        "        val_loss_discriminator = 0.0\n",
        "        generated_data_np = np.array(generated_data)\n",
        "        generated_data_reshaped = generated_data_np.reshape(-1, 64 * 64)\n",
        "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf_model.fit(generated_data, label.cpu().numpy())\n",
        "\n",
        "        # Initialize an empty list to store predictions on the validation set\n",
        "        predictions_valid = []\n",
        "        target_valid=[]\n",
        "\n",
        "        # Make predictions on the validation set using the trained random forest model\n",
        "        rf_model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in valid_loader:\n",
        "                # Validation forward pass for discriminator (similar to training loop, but only forward pass, no backward)\n",
        "                val_real_cpu = val_data[0].to(device)\n",
        "                b_size_val = val_real_cpu.size(0)\n",
        "                target_valid.append(val_data[1].to(device))\n",
        "                # Reshape the input if needed (adjust based on your model architecture)\n",
        "                val_real_cpu = val_real_cpu.view(b_size_val, -1)\n",
        "\n",
        "                # Make predictions on the validation set\n",
        "                val_output_rf = rf_model.predict(val_real_cpu.cpu().numpy())\n",
        "\n",
        "                # Collect predictions\n",
        "                predictions_valid.extend(val_output_rf)\n",
        "\n",
        "        # Calculate accuracy for the generator and random forest\n",
        "        accuracy_rf = accuracy_score(target_valid.cpu().numpy(), np.array(predictions_valid))\n",
        "        random_forest_accuracies.append(accuracy_rf)\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == EPOCH_NUM-1) and (i == len(train_loader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(viz_noise).detach().cpu()\n",
        "                display_images(fake)\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "# Find the generator with the highest random forest accuracy\n",
        "best_rf_generator_index = np.argmax(random_forest_accuracies)\n",
        "best_rf_generator_accuracy = random_forest_accuracies[best_rf_generator_index]\n",
        "\n",
        "print(f\"The best generator for Random Forest is G{best_rf_generator_index + 1} with accuracy: {best_rf_generator_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to plot training curves\n",
        "def plot_training_curves(G_losses_list, D_losses_list, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(G_losses_list, label='Generator Loss', alpha=0.7)\n",
        "    plt.plot(D_losses_list, label='Discriminator Loss', alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_curves(G_losses, D_losses, 'Model 1 Training Curves')\n",
        "with torch.no_grad():\n",
        "    fake_model = netG(viz_noise).detach().cpu()\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_model, padding=2, normalize=True), (1, 2, 0)))\n",
        "plt.title('Generated Samples - Model 1')"
      ],
      "metadata": {
        "id": "NCKETihmiwCL"
      },
      "id": "NCKETihmiwCL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3693bcd9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T18:23:15.221328Z",
          "iopub.status.busy": "2023-09-02T18:23:15.220990Z",
          "iopub.status.idle": "2023-09-02T18:23:15.729601Z",
          "shell.execute_reply": "2023-09-02T18:23:15.728620Z"
        },
        "papermill": {
          "duration": 0.537658,
          "end_time": "2023-09-02T18:23:15.733831",
          "exception": false,
          "start_time": "2023-09-02T18:23:15.196173",
          "status": "completed"
        },
        "tags": [],
        "id": "3693bcd9"
      },
      "outputs": [],
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(train_loader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Techniques for finetuning of GAN's"
      ],
      "metadata": {
        "id": "15F0xdwhHUrp"
      },
      "id": "15F0xdwhHUrp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Techniques:\n",
        "\n",
        "1. Layer Freezing: Leverage pre-trained features for domain adaptation by fixing lower discriminator layers while fine-tuning upper layers.\n",
        "2. Progressive Growing: Stabilize training and enhance high-quality image generation by starting low-resolution and gradually increasing complexity.\n",
        "3. Minibatch Discrimination: Improve training stability by calculating discriminator loss on a subset of samples in each minibatch.\n",
        "4. Trust-Region Optimization: Ensure safe exploration of the loss landscape with constrained updates during fine-tuning.\n"
      ],
      "metadata": {
        "id": "llL_m-BLTnNG"
      },
      "id": "llL_m-BLTnNG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specialized Techniques:\n",
        "\n",
        "1. Spectral Diversification: Prevent mode collapse and promote output diversity by penalizing similar generator outputs.\n",
        "2. Curriculum Learning: Guide the GAN towards better samples by gradually increasing training data difficulty.\n",
        "3. Pre-trained Embeddings: Inject domain-specific knowledge for controlled and interpretable outputs.\n",
        "4. Self-Attention Mechanisms: Improve long-range dependencies by allowing the model to focus on relevant image regions.\n",
        "5. Consistency Regularization: Encourage smooth transitions in the latent space by penalizing inconsistent outputs for perturbed inputs.\n",
        "6. Dynamic Learning Rates: Adapt learning rates to different model components and training stages for optimal performance.\n",
        "7. Mini-Batch Standard Deviation: Encourage diversity by incorporating mini-batch standard deviation in the discriminator.\n",
        "8. Label Smoothing: Prevent overconfidence in the discriminator by using slightly relaxed target labels (real and fake).\n",
        "9. Adversarial Dropout: Regularize the model during training by generating dropout masks adversarially.\n",
        "10. Ensemble Methods: Enhance robustness by combining outputs from multiple GANs with diverse architectures or initializations.\n",
        "11. Style-Based GANs: Provide better control over generated outputs by modeling style and content separately.\n",
        "12. Temporal GANs: Ensure smooth and realistic video sequences by incorporating temporal coherence constraints into the architecture.\n",
        "13. Dynamic Batch Sizes: Find an optimal balance between stability and efficiency by experimenting with dynamic batch sizes.\n",
        "14. GAN Inversion: Understand and control the latent space by mapping real images back to it using GAN inversion techniques.\n",
        "15. Dual Discriminator GANs: Balance realism and diversity by training with dual discriminators, one for each aspect.\n",
        "16. Task-Specific Loss Functions: Tailor loss functions to your specific task, such as perceptual loss for image translation or class-specific losses for conditional GANs."
      ],
      "metadata": {
        "id": "ik_WFgIDWvSz"
      },
      "id": "ik_WFgIDWvSz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quetion 3: Difference between Flask and Fastapi"
      ],
      "metadata": {
        "id": "Z4Hu4I9zHdml"
      },
      "id": "Z4Hu4I9zHdml"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About Flask and FastAPI\n",
        "Flask, a micro-framework established in 2010, is known for its simplicity and flexibility, suitable for small to medium-sized web applications. FastAPI, introduced in 2019, is a modern framework designed for building high-performance APIs with Python 3.6+. It prioritizes speed, simplicity, and adherence to the OpenAPI standard. Both frameworks have distinct strengths, with Flask offering simplicity and flexibility, while FastAPI excels in building efficient APIs with minimal code.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0BoPVwodR3t3"
      },
      "id": "0BoPVwodR3t3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Difference between Flask and FastAPI\n",
        "The key differences between Flask and FastAPI are:\n",
        "* Flask is a micro-framework, while FastAPI is a full-stack framework.\n",
        "* FastAPI is designed for building APIs, while Flask can be used for building web applications and APIs.\n",
        "* FastAPI is faster than Flask due to its asynchronous code and type annotations.\n",
        "* FastAPI has automatic data validation and documentation, while Flask requires manual validation and documentation.\n",
        "* Flask has a larger community and ecosystem than FastAPI."
      ],
      "metadata": {
        "id": "Wp409DBxSZoZ"
      },
      "id": "Wp409DBxSZoZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4: Benifits of using docker"
      ],
      "metadata": {
        "id": "7vhUzxQEHdh0"
      },
      "id": "7vhUzxQEHdh0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Docker?\n",
        "Docker is a containerization platform that has become increasingly popular in recent years, particularly in the world of DevOps and cloud computing. Docker provides a range of benefits for developers and operations teams, including increased efficiency, flexibility, and portability."
      ],
      "metadata": {
        "id": "ZnRw1Ff1S2TO"
      },
      "id": "ZnRw1Ff1S2TO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benifits of using Docker\n",
        "1. Consistency and repeatability:\n",
        "2. Docker allows developers to package applications and dependencies into containers, ensuring that they run consistently across different environments. This makes it easy to create reproducible builds, reducing the risk of bugs and errors caused by differences in environment configurations. With Docker, developers can be confident that their applications will run the same way in development, testing, and production environments.\n",
        "3. Improved efficiency and resource utilization:\n",
        "4. Docker allows multiple containers to run on a single host machine, allowing for more efficient use of resources. Each container has its own isolated environment, so applications can be scaled up or down quickly and easily, without impacting other applications running on the same host. This means that organizations can maximize their infrastructure utilization, reduce costs, and improve overall efficiency.\n",
        "5. Faster development and deployment:\n",
        "6. Docker streamlines the development and deployment process by making it easy to build, test, and deploy applications in containers. Developers can quickly spin up containers to test changes and experiment with new features, without having to set up a full development environment. Once an application is ready to be deployed, it can be packaged into a container and distributed to any environment, making it easy to deploy applications consistently across different environments.\n",
        "7. Increased flexibility and portability:\n",
        "8. Docker containers are designed to be portable, meaning they can run on any host machine that has Docker installed. This makes it easy to move applications between different environments, whether it's from a developer's laptop to a test environment, or from a test environment to a production environment. Docker also makes it easy to manage dependencies, as all the necessary components are included in the container.\n",
        "9. Improved security:\n",
        "10. Docker containers provide a more secure environment for running applications, as each container is isolated from the host system and other containers. This reduces the risk of one application impacting another or of an attacker gaining access to the host system. Docker also makes it easy to distribute updates and patches to applications, ensuring that they are always running on the latest version and are protected against known vulnerabilities.\n",
        "11. One of the main advantages of using Docker is that it allows developers to isolate applications from the underlying infrastructure, reducing the risk of conflicts and making it easier to manage dependencies. Docker also makes it easy to scale applications up or down, as containers can be started and stopped quickly and easily."
      ],
      "metadata": {
        "id": "rAjV_E5fS3rK"
      },
      "id": "rAjV_E5fS3rK"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 291.95034,
      "end_time": "2023-09-02T18:23:18.196793",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-09-02T18:18:26.246453",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "15F0xdwhHUrp",
        "Z4Hu4I9zHdml",
        "7vhUzxQEHdh0"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}